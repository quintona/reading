\documentclass{article}

\input{base.tex}


\begin{document}

\section{Ideas}

Take the concept of the lambda architecture to the next logical level, which is using combining batch and realtime DBs, together with combining eventual with strongly consistent databases, and expose them via a single query planner and interface. Thus expose a DB that beats the CAP theorem entirely. 

A generalised query layer that allows you to query across database. This would be the generalisation of the idea above, and obivously more generally applicable. The query planner would be really interesting, especially given notional materialized views across database.

\section{Notes on Papers}

\subsection{Database}

\subsubsection{LINVIEW: Incremental View Maintenance for Complex Analytical
               Queries}

\textbf{Article reference:} \cite{DBLP:journals/corr/NikolicEK14}

The article has 2 interesting aspects, firstly they present a framework for incremental maintenance of algrebra applications. Incremental in the sense that incremental materialized views can be generated as an optimisation, especially in cases where expensive matrix multiplication is involved. 

Secondly the article presents a compiler that generates spark code that implements the algebra logic which is defined in either R or some other language. 

\textbf{Thoughts:} There are some high level take aways from this, which I need to consider:
\begin{itemize}
  \item There is an entire world of research into incremental optimisations. This will be required in order to fully support a lambda approach, I suspect. In the high level idea of combining different DBs of different attributes, various optimisation techniques will be required out of the box
  \item The notion of generating this kind of code is also interesting, I would need to do some more reading into compiler theory, or rather macros within scala. I doubt I would build a compiler toolchain, but rather use standard scala structures for this. 
\end{itemize}

\subsubsection{Exploiting Opportunistic Physical Design in Large-scale
               Data Analytics}

\textbf{Article Reference:} \cite{DBLP:journals/corr/abs-1303-6609}

\subsubsection{MISO: souping up big data query processing with a multistore system}

\textbf{Arcticle Reference:} \cite{LeFevre:2014:MSU:2588555.2588568}

Multistore systems utilize multiple distinct data stores such as Hadoop's HDFS and an RDBMS for query processing by allowing a query to access data and computation in both stores. Current approaches to multistore query processing fail to achieve the full potential benefits of utilizing both systems due to the high cost of data movement and loading between the stores. Tuning the physical design of a multistore, i.e., deciding what data resides in which store, can reduce the amount of data movement during query processing, which is crucial for good multistore performance. In this work, we provide what we believe to be the first method to tune the physical design of a multistore system, by focusing on which store to place data. Our method, called MISO for MultISstore Online tuning, is adaptive, lightweight, and works in an online fashion utilizing only the by-products of query processing, which we term as opportunistic views. We show that MISO significantly improves the performance of ad-hoc big data query processing by leveraging the specific characteristics of the individual stores while incurring little additional overhead on the stores.

\textbf{Thoughts:} This is exactly in line with what I was thinking, with a focus on the consistency aspects and some algrebras.

\subsubsection{SPANStore: Cost-effective Geo-replicated Storage Spanning Multiple Cloud Services}

\textbf{Arcticle Reference:} \cite{Wu:2013:SCG:2517349.2522730}



\subsection{Algebra}

\subsubsection{Distributivity versus associativity in the homology theory of algebraic structures}

\textbf{Article Reference:} \cite{2011arXiv1109.4850P}

\subsection{programming}

\subsubsection{General thoughts}

\begin{itemize}
  \item Can't define a functor for set, because of the constraint on the type. Thus coyoneda. 
  \item Functor is something you can define a map on. 
  \item Monad is something you can define a flatmap on (bind)
  \item Once you have a functor, you can construct a free monad
  \item An identity is used to start things unravelling. Recursive case, at the next level. 
\end{itemize}

\subsubsection{Reflection without remorse}

\textbf{Article Reference:} \cite{conf/haskell/PloegKiselyov14}

\textbf{From Article:}

A series of list appends or monadic binds for many monads performs algorithmically worse when left-associated. Continuation- passing style (CPS) is well-known to cure this severe dependence of performance on the association pattern. The advantage of CPS dwindles or disappears if we have to examine or modify the intermediate result of a series of appends or binds, before continuing the series. Such examination is frequently needed, for example, to control search in non-determinism monads.

For example, in the expression (x ++ y) ++ z, the list x must be traversed twice: it occurs twice in a left hand side argument to +. Hence, this expression runs in in 2|x| + |y| + 2 steps, whereas the equivalent expression x ++ (y ++ z) runs in just |x| + |y| + 2 steps. In this way, a wrong grouping of expressions involving ++ can easily lead to severe performance problems. 

In general, the problem occurs with any associative (or satisfying the associativity monad law) operator (⊕) that traverses its left argument but not its right argument that operates on some recursive2 data type. In this situation, (x ⊕ y) ⊕ z costs |x| more steps to eval- uate than x ⊕ (y ⊕ z), where |x| is now the number of values of type X inside x that are non-terminal (i.e. they are not for example the empty list or a leaf). Repeated application of such an operator can lead to asymptotic running time overhead if |a⊕b| ≥ |a|+|b|

We cannot expect the programmer to only form right- associated expressions, especially when using laziness: the pro- grammer must then make sure that every time the operator is used, the left hand side cannot be itself a result of this operator.

A benefit of using type aligned sequences in this way, instead of directly using regular sequences, is that type aligned sequences rule out a class of implementation bugs: the types in a type aligned sequence enforce the ordering of the elements. Hence, accidentally switching two elements will result in a type error, as the resulting sequence may not be a path. In contrast, in regular sequences the types do not enforce the ordering of the elements and an accidental change of order in, for instance, the definition of concatenation would have gone unnoticed by the type checker.

\textbf{Thoughts:}

So the key issue is that the left associativity, under certain circumstances can cause a real performance problem. CPS is often used as a means to deal with this issue, however we can't inspect the operations (reflect) without great cost even when using CPS, and in the case of Monadic contexts this is often extremely useful (think reactive). Reflect essentially means alternate between observing and building.

I am clearly missing something with regards to laziness and left associativity. Must go find some more information on this front. 

Type aligned sequences and free is worth reading more on. The type aligned conept in terms of operation ordering is really interesting, especially when we mix it with the concepts of planning and function fusion. Describing the computation where you strongly determine the order.

TAS - key point is to reify the functions, the composition is problem when you combine too many flatmap.

\subsubsection{Lift}

\textbf{Taken from}: \href{http://stackoverflow.com/questions/17965059/what-is-lifting-in-scala}{Stack Overflow}

There are a few usages:

\textbf{PartialFunction}


Remember a `PartialFunction[A, B]` is a function defined for some subset of the domain `A` (as specified by the `isDefinedAt` method). You can "lift" a `PartialFunction[A, B]` into a `Function[A, Option[B]]`. That is, a function defined over the *whole* of `A` but whose values are of type `Option[B]`

This is done by the explicit invocation of the method `lift` on `PartialFunction`.

\begin{minted}{scala}
    scala> val pf: PartialFunction[Int, Boolean] = 
          { case i if i > 0 => i % 2 == 0}
    pf: PartialFunction[Int,Boolean] = <function1>

    scala> pf.lift
    res1: Int => Option[Boolean] = <function1>

    scala> res1(-1)
    res2: Option[Boolean] = None

    scala> res1(1)
    res3: Option[Boolean] = Some(false)
\end{minted}

\textbf{Methods}

You can "lift" a method invocation into a function. This is called *eta-expansion* (thanks to Ben James for this). So for example:

\begin{minted}{scala}
    scala> def times2(i: Int) = i * 2
    times2: (i: Int)Int
\end{minted}

We lift a method into a function by applying the \textbf{underscore}

\begin{minted}{scala}
    scala> val f = times2 _
    f: Int => Int = <function1>

    scala> f(4)
    res0: Int = 8
\end{minted}

Note the fundamental difference between methods and functions. `res0` is an \textbf{instance} (i.e. it is a \textbf{value}) of the (function) type `(Int => Int)`

\textbf{Functors}

A *functor* (as defined by **scalaz**) is some "container" (I use the term *extremely* loosely), `F` such that, if we have an `F[A]` and a function `A => B`, then we can get our hands on an `F[B]` (think, for example, `F = List` and the `map` method)

We can encode this property as follows:

\begin{minted}{scala}
    trait Functor[F[_]] { 
      def map[A, B](fa: F[A])(f: A => B): F[B]
    }
\end{minted}

This is isomorphic to being able to "lift" the function `A => B` into the domain of the functor. That is:

\begin{minted}{scala}
    def lift[F[_]: Functor, A, B](f: A => B): F[A] => F[B]
\end{minted}

That is, if `F` is a functor, and we have a function `A => B`, we have a function `F[A] => F[B]`. You might try and implement the `lift` method - it's pretty trivial.

\textbf{Monad Transformers}

As *hcoopz* says below (and I've just realized that this would have saved me from writing a ton of unnecessary code), the term "lift" also has a meaning within **Monad Transformers**. Recall that a monad transformers are a way of "stacking" monads on top of each other (monads do not compose).

So for example, suppose you have a function which returns an `IO[Stream[A]]`. This can be converted to the monad transformer `StreamT[IO, A]`. Now you may wish to "lift" some other value an `IO[B]` perhaps to that it is also a `StreamT`. You could either write this:
\begin{minted}{scala}
    StreamT.fromStream(iob map (b => Stream(b)))
\end{minted}

Or this:
\begin{minted}{scala}
    iob.liftM[StreamT]
\end{minted}    

this begs the question: *why do I want to convert an `IO[B]` into a `StreamT[IO, B]`?*. The answer would be "to take advantage of composition possibilities". Let's say you have a function `f: (A, B) => C`

\begin{minted}{scala}
    lazy val f: (A, B) => C = ???
    val cs = 
      for {
        a <- as                //as is a StreamT[IO, A]
        b <- bs.liftM[StreamT] //bs was just an IO[B]
      }
      yield f(a, b)

    cs.toStream //is a Stream[IO[C]], cs was a StreamT[IO, C]
\end{minted}

\bibliographystyle{plain}
\bibliography{articles.bib}
Reflection without Remorse
